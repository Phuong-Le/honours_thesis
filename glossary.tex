\setglossarypreamble{This list contains the most relevant versions of definitions to this research project}
\makeglossaries

\newglossaryentry{gle}
{
        name=GLE,
        description={(Genomic Location Effect) \\ the influence of a nucleotide's location on the tendency for it to mutate}
}

\newglossaryentry{nucleotide}
{
        name=nucleotide,
        description={same as base; a component of the DNA sequence, \textit{e.g.} A for adenine}
}

\newglossaryentry{base}
{
        name=base,
        description={same as nucleotide; a component of the DNA sequence, \textit{e.g.} A for adenine}
}

\newglossaryentry{sce}
{
        name=SCE,
        description={(Sequence Context Effect) \\ the influence of the flanking bases on a nucleotide's location on the tendency for it to mutate}
}

\newglossaryentry{or}
{
        name=$OR$,
        description={(Odds ratio) \\ a statistic that measures the degree bias for two characteristics to occur. In my case, I measured how mutations favour closed over open chromatin regions}
}

\newglossaryentry{glm}
{
        name=$GLM$,
        description={(Generalised Linear Model) \\ A class of model that allows the errors (residuals) to follow a different distribution than the normal distribution. The ordinary linear model is one example of this class}
}

\newglossaryentry{pcawg}
{
        name=PCAWG,
        description={(Pan-cancer analysis of whole genome) \\ an international project that sequenced samples of different cancer types. Part of the project also identified somatic mutations and passenger mutations, which I used during my Honours}
}

\newglossaryentry{icgc}
{
        name=ICGC,
        description={(International Cancer Genome Consortium) \\ an organisation that contributes to the PCAWG project. Access to the mutation file (\textit{i.e.} non US data) from ICGC is not restricted}
}

\newglossaryentry{tcga}
{
        name=TCGA,
        description={(The Cancer Genome Atlas) \\ another contributor to the PCAWG project. Access to the mutation file (\textit{i.e.} US data) from TCGA is restricted}
}

\newglossaryentry{encode}
{
        name=ENCODE,
        description={(Encyclopedia of DNA Elements) \\ a project that studies various genetics and epigenetics data}
}

\newglossaryentry{dhs}
{
        name=DHS,
        description={(DNase Hypersensitivity) \\ a measure of chromatin status - how accessible a genomic region is. This project used data from ENCODE For DHS}
}

\newglossaryentry{null}
{
        name=$H_o$,
        description={(Null hypothesis) \\ The null hypothesis assumes a certain characteristic is the same between 2 or more different classes}
}

\newglossaryentry{alternative}
{
        name=$H_a$,
        description={(Alternative hypothesis) \\ The alternative hypothesis assumes a certain characteristic is different between 2 or more different given classes.}
}

\newglossaryentry{f1}
{
        name=$F_1$,
        description={(F1-Score) \\ A measure of accuracy that takes into account both the sensitivity and specificity of the classifier}
}

\newglossaryentry{sensitivity}
{
        name=sensitivity,
        description={a measure of accuracy for how well a classifier can identify certain classes. The sensitivity for a class is the ratio between the number of observations correctly identified and the total number of observations available for that class}
}

\newglossaryentry{specificity}
{
        name=specificity,
        description={a measure of accuracy for how well a classifier can exclude the possibility of other classes when identifying certain classes. The specificity for a class is the ratio between the number of observations correctly identified as that class and the total number of observations identified as that class}
}

\newglossaryentry{ml}
{
        name=ML,
        description={(Machine Learning) \\ the process of building a model to learn the patterns of data}
}

\newglossaryentry{model}
{
        name=model,
        description={all the statistical assumptions about the properties and patterns of data}
}

\newglossaryentry{classifier}
{
        name=classifier,
        description={a model that predict categorical data. In other words, the responses of the model are categorical, not numeric}
}

\newglossaryentry{kde}
{
        name=KDE,
        description={(Kernel Density Estimation) \\ the use of a kernel function to estimate the density of a particular data point}
}

\newglossaryentry{kernel function}
{
        name=kernel function,
        description={any function that belongs to a class of non-negative functions commonly used in density estimation and computation of ``similarity'' between 2 vectors}
}

\newglossaryentry{density}
{
        name=density,
        description={the density measures the likelihood of finding data $f(x)$ at a particular location $x$. The density throughout the domain of the data is restricted to be 1}
}

\newglossaryentry{intensity}
{
        name=intensity,
        description={the intensity of a data point is the product of its density and the sample size of the data. Accordingly, while ``inheriting'' some characteristics of the density, the intensity throughout the domain of the data is not restricted to be 1}
}

\newglossaryentry{knn}
{
        name=KNN,
        description={($k$-nearest neighbours) \\ a machine learning algorithm that predicts the labels of a data point based on the information from the closest data points to it. The number of closest data points $k$ is a hyper-parameter to be pre-defined. The choice of the distance measures used to identify the closest data points usually depend on the nature of the data}
}

\newglossaryentry{pval}
{
        name=$p-value$,
        description={the probability for an event to occur assuming the null hypothesis $H_o$ is true. The smaller the $p-value$, the more evidence we have to reject the null hypothesis}
}

\newglossaryentry{jackknife}
{
        name=jackknife,
        description={a statistical re-sampling technique which is generally used to estimate the variance in a particular statistic of a data sample. This technique re-computes the statistic of interest upon removing one data point from the given sample. The departure of the re-computed statistic from the original statistic indicates how extreme and influential the removed data point is. Repeating the procedure for every data point outputs a collection of re-computed statistics, which represents the estimated range for that statistic}
}

\newglossaryentry{bootstrap}
{
        name=bootstrap,
        description={a statistical re-sampling technique that reconstructs the original data set by randomly drawing data points from that original data set. The idea is that the reconstructed data set should inherit the properties of the original set, and the departure arises mainly from random noise. Similar to the jackknife, the bootstrap can be used to estimate data variance. However, in this project, the bootstrap was used for hypothesis testing}
}